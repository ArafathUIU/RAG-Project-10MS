{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzV3v0tDX3KQ",
        "outputId": "fa07e5f8-bff7-4036-9673-3f1cb6fbcceb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils tesseract-ocr-ben\n",
            "0 upgraded, 2 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 702 kB of archives.\n",
            "After this operation, 1,568 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.8 [186 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-ben all 1:4.00~git30-7274cfa-1.1 [516 kB]\n",
            "Fetched 702 kB in 1s (1,148 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 126284 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.8_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.8) ...\n",
            "Selecting previously unselected package tesseract-ocr-ben.\n",
            "Preparing to unpack .../tesseract-ocr-ben_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-ben (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-ben (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.8) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0.post1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (25.0)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.3.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.53.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.16.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.33.4)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.7.14)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Downloading faiss_cpu-1.11.0.post1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytesseract, pdf2image, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, faiss-cpu, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed faiss-cpu-1.11.0.post1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pdf2image-1.17.0 pytesseract-0.3.13\n"
          ]
        }
      ],
      "source": [
        "!apt-get install -y tesseract-ocr tesseract-ocr-ben poppler-utils\n",
        "!pip install pytesseract pdf2image sentence-transformers faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-egMzLYXnNN",
        "outputId": "77dd4aec-43ce-483c-d203-adbed1b35492"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>We are using cuda device.<<\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import os\n",
        "import faiss\n",
        "import numpy as np\n",
        "import pickle\n",
        "import openai\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from tqdm import tqdm\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "from openai import OpenAI\n",
        "from torch.nn.functional import softmax\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\">>We are using {device} device.<<\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "XjG5QH5uYYzp",
        "outputId": "2f8c7737-4f6d-4211-87b1-10d147ee7afe"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-91ca557c-6eb5-4c12-91f4-b47ce11ee5bf\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-91ca557c-6eb5-4c12-91f4-b47ce11ee5bf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving HSC26-Bangla1st-Paper.pdf to HSC26-Bangla1st-Paper.pdf\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soMKGOSFXww3",
        "outputId": "a0e2fae6-5ea0-45ae-c7ec-3a9ca4ff97dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total pages: 49\n"
          ]
        }
      ],
      "source": [
        "from pdf2image import convert_from_path\n",
        "\n",
        "pages = convert_from_path(\"/content/HSC26-Bangla1st-Paper.pdf\", dpi=300)\n",
        "print(f\"Total pages: {len(pages)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdBEk_XPZnV2",
        "outputId": "aa229417-58e0-49b2-a813-8e54d0a9a307"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed page 1\n",
            "Processed page 2\n",
            "Processed page 3\n",
            "Processed page 4\n",
            "Processed page 5\n",
            "Processed page 6\n",
            "Processed page 7\n",
            "Processed page 8\n",
            "Processed page 9\n",
            "Processed page 10\n",
            "Processed page 11\n",
            "Processed page 12\n",
            "Processed page 13\n",
            "Processed page 14\n",
            "Processed page 15\n",
            "Processed page 16\n",
            "Processed page 17\n",
            "Processed page 18\n",
            "Processed page 19\n",
            "Processed page 20\n",
            "Processed page 21\n",
            "Processed page 22\n",
            "Processed page 23\n",
            "Processed page 24\n",
            "Processed page 25\n",
            "Processed page 26\n",
            "Processed page 27\n",
            "Processed page 28\n",
            "Processed page 29\n",
            "Processed page 30\n",
            "Processed page 31\n",
            "Processed page 32\n",
            "Processed page 33\n",
            "Processed page 34\n",
            "Processed page 35\n",
            "Processed page 36\n",
            "Processed page 37\n",
            "Processed page 38\n",
            "Processed page 39\n",
            "Processed page 40\n",
            "Processed page 41\n",
            "Processed page 42\n",
            "Processed page 43\n",
            "Processed page 44\n",
            "Processed page 45\n",
            "Processed page 46\n",
            "Processed page 47\n",
            "Processed page 48\n",
            "Processed page 49\n"
          ]
        }
      ],
      "source": [
        "import pytesseract\n",
        "from pdf2image import convert_from_path\n",
        "import os\n",
        "\n",
        "# === CONFIG ===\n",
        "pdf_path = \"/content/HSC26-Bangla1st-Paper.pdf\"\n",
        "image_folder = \"ocr_images\"\n",
        "text_folder = \"ocr_texts\"\n",
        "\n",
        "# === Step 1: Create output directories ===\n",
        "os.makedirs(image_folder, exist_ok=True)\n",
        "os.makedirs(text_folder, exist_ok=True)\n",
        "\n",
        "# === Step 2: Convert PDF pages to images ===\n",
        "pages = convert_from_path(pdf_path, dpi=300)\n",
        "\n",
        "# === Step 3: Save images and extract text ===\n",
        "for i, page in enumerate(pages):\n",
        "    image_path = os.path.join(image_folder, f\"page_{i+1}.png\")\n",
        "    text_path = os.path.join(text_folder, f\"output_{i+1}.txt\")\n",
        "\n",
        "    page.save(image_path, \"PNG\")\n",
        "\n",
        "    # Apply Tesseract OCR with Bengali language\n",
        "    text = pytesseract.image_to_string(image_path, lang='ben')\n",
        "\n",
        "    # Save OCR text\n",
        "    with open(text_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(text)\n",
        "\n",
        "    print(f\"Processed page {i+1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "337D9fHXZr3q"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def clean_bangla_text(text):\n",
        "    # Remove unwanted characters (non-Bangla, non-punctuation, non-space)\n",
        "    text = re.sub(r'[^\\u0980-\\u09FF\\s।,?!\\n]+', '', text)\n",
        "    # Normalize excessive whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJyk98tmZ1W-",
        "outputId": "d42440db-892e-4e7c-8387-4ca213eae5ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Cleaned: /content/ocr_texts/output_1.txt → /content/ocr_texts/cleaned_output_1.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_2.txt → /content/ocr_texts/cleaned_output_2.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_3.txt → /content/ocr_texts/cleaned_output_3.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_4.txt → /content/ocr_texts/cleaned_output_4.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_5.txt → /content/ocr_texts/cleaned_output_5.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_6.txt → /content/ocr_texts/cleaned_output_6.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_7.txt → /content/ocr_texts/cleaned_output_7.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_8.txt → /content/ocr_texts/cleaned_output_8.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_9.txt → /content/ocr_texts/cleaned_output_9.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_10.txt → /content/ocr_texts/cleaned_output_10.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_11.txt → /content/ocr_texts/cleaned_output_11.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_12.txt → /content/ocr_texts/cleaned_output_12.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_13.txt → /content/ocr_texts/cleaned_output_13.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_14.txt → /content/ocr_texts/cleaned_output_14.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_15.txt → /content/ocr_texts/cleaned_output_15.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_16.txt → /content/ocr_texts/cleaned_output_16.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_17.txt → /content/ocr_texts/cleaned_output_17.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_18.txt → /content/ocr_texts/cleaned_output_18.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_19.txt → /content/ocr_texts/cleaned_output_19.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_20.txt → /content/ocr_texts/cleaned_output_20.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_21.txt → /content/ocr_texts/cleaned_output_21.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_22.txt → /content/ocr_texts/cleaned_output_22.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_23.txt → /content/ocr_texts/cleaned_output_23.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_24.txt → /content/ocr_texts/cleaned_output_24.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_25.txt → /content/ocr_texts/cleaned_output_25.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_26.txt → /content/ocr_texts/cleaned_output_26.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_27.txt → /content/ocr_texts/cleaned_output_27.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_28.txt → /content/ocr_texts/cleaned_output_28.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_29.txt → /content/ocr_texts/cleaned_output_29.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_30.txt → /content/ocr_texts/cleaned_output_30.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_31.txt → /content/ocr_texts/cleaned_output_31.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_32.txt → /content/ocr_texts/cleaned_output_32.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_33.txt → /content/ocr_texts/cleaned_output_33.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_34.txt → /content/ocr_texts/cleaned_output_34.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_35.txt → /content/ocr_texts/cleaned_output_35.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_36.txt → /content/ocr_texts/cleaned_output_36.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_37.txt → /content/ocr_texts/cleaned_output_37.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_38.txt → /content/ocr_texts/cleaned_output_38.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_39.txt → /content/ocr_texts/cleaned_output_39.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_40.txt → /content/ocr_texts/cleaned_output_40.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_41.txt → /content/ocr_texts/cleaned_output_41.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_42.txt → /content/ocr_texts/cleaned_output_42.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_43.txt → /content/ocr_texts/cleaned_output_43.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_44.txt → /content/ocr_texts/cleaned_output_44.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_45.txt → /content/ocr_texts/cleaned_output_45.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_46.txt → /content/ocr_texts/cleaned_output_46.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_47.txt → /content/ocr_texts/cleaned_output_47.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_48.txt → /content/ocr_texts/cleaned_output_48.txt\n",
            "✅ Cleaned: /content/ocr_texts/output_49.txt → /content/ocr_texts/cleaned_output_49.txt\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def clean_bangla_text(text):\n",
        "    # Remove unwanted characters (non-Bangla, non-punctuation, non-space)\n",
        "    text = re.sub(r'[^\\u0980-\\u09FF\\s।,?!\\n]+', '', text)\n",
        "    # Normalize excessive whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "output_dir = \"/content/ocr_texts\"  # or specify full path like \"./ocr_texts/\"\n",
        "\n",
        "# Fix: Iterate from 1 to len(pages) inclusive to match the file names\n",
        "for i in range(1, len(pages) + 1):\n",
        "    input_file = os.path.join(output_dir, f\"output_{i}.txt\")\n",
        "    output_file = os.path.join(output_dir, f\"cleaned_output_{i}.txt\")\n",
        "\n",
        "    # Read original OCR text\n",
        "    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
        "        raw_text = f.read()\n",
        "\n",
        "    # Clean it\n",
        "    cleaned_text = clean_bangla_text(raw_text)\n",
        "\n",
        "    # Save cleaned version\n",
        "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(cleaned_text)\n",
        "\n",
        "    print(f\"✅ Cleaned: {input_file} → {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0wSe3btMcVUe"
      },
      "outputs": [],
      "source": [
        "with open(\"all_cleaned_text.txt\", \"w\", encoding=\"utf-8\") as merged:\n",
        "    for i in range(1, len(pages) + 1):\n",
        "        with open(f\"/content/ocr_texts/cleaned_output_{i}.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "            merged.write(f.read() + \"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "l6nRZ1rFc4GV"
      },
      "outputs": [],
      "source": [
        "with open(\"all_cleaned_text.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_text = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "G8KqTJkGdIDn"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=800,\n",
        "    chunk_overlap=100,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \"।\", \" \", \"\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "5D1YfCXCdVSH"
      },
      "outputs": [],
      "source": [
        "chunks = text_splitter.split_text(raw_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gakteBdZdaKf",
        "outputId": "42144947-b7dc-45e4-ef01-2fa8e122c802"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Total chunks created: 131\n",
            "\n",
            "--- Chunk 1 ---\n",
            "অনলাইন ব্যাট হি বাংলা ইংরেজি আইসিটি অনলাইন ব্যাচ সম্পর্কিত যেকোনো জিজ্ঞাসায়, ,...\n",
            "\n",
            "--- Chunk 2 ---\n",
            "লুল জআললাইন ব্যাচ ১? নিম্নবিত্ত ব্যক্তির হঠাৎ বিত্তশালী হয়ে ওঠার ফলে সমাজে পরিচয় সংকট সম্পর্কে ধারণা লাভ করবে। ৮ তৎকালীন সমাজসভ্যতা ও মানবতার অবমাননা সম্পর্কে জানতে পারবে। ৮ তৎকালীন সমাজের পণপ্রথার কুপ্রভাব সম্পর্কে জানতে পারবে। ৮ তৎকালে সমাজে ভদ্রলোকের স্বভাববৈশিষ্ট্য সম্পর্কে জ্ঞানলাভ করবে৷ ৮ নারী কোমল ঠিক, কিন্তু দুর্বল নয় কল্যাণীর জীবনচরিত দ্বারা প্রতিষ্ঠিত এই সত্য অনুধাবন করতে পারবে। ৮ মান...\n",
            "\n",
            "--- Chunk 3 ---\n",
            "। পিতৃহীন দীপুর চাচাই ছিলেন পরিবারের কর্তা। দীপু শিক্ষিত হলেও তার সিদ্ধান্ত নেওয়ার ক্ষমতা ছিল না। চাচা তার বিয়ের উদ্যোগ নিলেও যৌতুক নিয়ে বাড়াবাড়ি করার কারণে কন্যার পিতা অপমানিত বোধ করে বিয়ের আলোচনা ভেঙে দেন। দীপু মেয়েটির ছবি দেখে মুগ্ধ হলেও তার চাচাকে কিছুই বলতে পারেননি। ৩। দীপুর চাচার সঙ্গে অপরিচিতা গন্সের কোন চরিত্রের মিল আছে? ক হরিশের খ মামার গ শিক্ষকের ঘ বিনুর ৪ উক্ত চরিত্রে প্রাধান্য প...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"✅ Total chunks created: {len(chunks)}\\n\")\n",
        "for i, chunk in enumerate(chunks[:3]):\n",
        "  print(f\"--- Chunk {i+1} ---\\n{chunk[:400]}...\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "dDMBxL2zdcgo"
      },
      "outputs": [],
      "source": [
        "df_filtered = pd.DataFrame({\"Text\": chunks})\n",
        "\n",
        "# Save for manual translation or review\n",
        "df_filtered.to_csv(\"bangla_text.csv\", index=False, encoding=\"utf-8-sig\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56pmQZDFdiI4"
      },
      "outputs": [],
      "source": [
        "##Clean the CSV for more Clearence and named 10MS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "5BtwVG9AduO5"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/10ms - Sheet1 (2).csv')\n",
        "df['word_count'] = df['Text'].astype(str).apply(lambda x: len(x.split()))\n",
        "\n",
        "df_filtered = df[df['word_count'] <= 600].copy()\n",
        "df_filtered = df_filtered.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "FMNcR3Wud6RL",
        "outputId": "9e6f109b-f700-4dab-b95e-9d7fd6ce840d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'বিনুদা ফিরিয়া আসিয়া বলিলেন,মন্দ নয় হে খাটি সোনা বটে বিনুদাদার ভাষাটা অত্যন্ত আঁট যেখানে আমরা বলি চমৎকার সেখানে তিনি বলেন চলনসই অতএব বুঝিলাম আমার ভাগ্যে প্রজাপতির সঙ্গে পঞ্চশরের কোনো বিরোধ নাই বলা বাহুল্য বিবাহ উপলক্ষে কন্যাপক্ষকেই কলকাতা আসিতে হইল কন্যার পিতা শস্তুনাথবাবু হরিশকে কত বিশ্বাস করেন তাহার প্রমাণ এই যে বিবাহের তিন দিন পূর্বে তিনি আমাকে চক্ষে দেখেন এবং আশীর্বাদ করিয়া যান বয়স তার চল্লিশের কিছু এপারে বা ওপারে চুল কীচা গোঁফে পাক ধরিতে আরম্ভ করিয়াছে মাত্র সুপুরুষ বটে ভিড়ের মধ্যে দেখিলে সকলের আগে তার উপরে চোখ পড়িবার মতো চেহারা আশা করি আমাকে দেখিয়া তিনি খুশি হইয়াছিলেন বোঝা শক্ত কেননা তিনি বড়ই চুপচাপ যে দুটি একটি কথা বলেন তাহাতে যেন পুরা জোর দেন না মামার মুখ তখন অনর্গল ছুটিতেছিল ধনে মানে আমাদের স্থান শহরের কারো চেয়ে কম নয় এই কথাই তিনি নানা প্রসঙ্গে প্রচার করিতেছিলেন শস্তুনাথবাবু কোনো ফাঁকে হু হ্যা কিছুই বলেননি মামাকে দমানো শক্ত তিনি শস্তুনাথবাবুর চুপ ভাব দেখে ভাবিলেন লোকটা নিতান্ত নিজীব একেবারে কোনো তেজ নাই বেহাইসম্পদায়ে তেজ থাকাটা দোষের অতএব মামা মনে মনে খুশি হইলেন শস্তুনাথবাবু যখন উঠিলেন তখন মামা উপর থেকেই সংক্ষেপে বিদায় দিলেন গাড়িতে তুলিতে গেলেন না পণ সম্বন্ধে দুই পক্ষে পাকাপাকি কথা ঠিক হইয়া গিয়াছিল মামা নিজেকে অসামান্য চতুর বলিয়াই অভিমান করিয়া থাকেন কথাবার্তায় কোথাও কিছু ফাঁক রাখেন নাই টাকার অঙ্ক তো স্থির ছিলই তারপরে গহনা কত ভরি সোনা কত দরে হইবে সেটাও বাঁধাবিধি হইয়া গিয়াছিল আমি এই দেনাপাওনার কথায় ছিলাম না জানিতাম না কিন্তু বুঝিতাম এই অংশটাও বিবাহের একটি প্রধান অংশ এবং যার উপর দায়িত্ব সে এক কড়াও ঠকিবেন না মামা আশ্চর্য পাকা লোক বলিয়া আমাদের সংসারের প্রধান গর্ব যেখানে আমাদের কোনো সম্বন্ধ আছে সেখানে তিনি বুদ্ধির লড়াইয়ে জিতিবেন এই একেবারে ধরা কথা আমাদের অভাব না থাকিলেও এবং অন্য পক্ষের অভাব থাকিলেও জিতিব এই আমাদের সংসারের জেদ গায়েহলুদ অসম্ভব রকম ধুম করিয়া গেল বাহক এত যে তার আদমশুমারি করিতে কেরানি লাগিবে তাহাদিগকে বিদায় দিতে অন্য পক্ষকে যে নাকাল হইতে হইবে এই কথা স্মরণ করিয়া মামার সঙ্গে মা একযোগে বিস্তর হাসিলেন ব্যান্ড বাঁশি শখের কন্দর্ট প্রভৃতি যেখানে যত উচ্চ শব্দ আছে সমস্ত একসঙ্গে সংগীত সরস্বতীর পদ্মবন দলিত বিদলিত করিয়া তুলিলাম আংটি হার জরিজহরতে মনে হইল ভাবি জামাইয়ের মূল্য যেন সর্বাঙ্গে স্পষ্ট করিয়া লিখিয়া ভাবী শ্বশুরের সঙ্গে মোকাবিলা করিতে চলিয়াছিলাম।\\n'"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_filtered['Text'][7]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "59UEQn2xeBPG"
      },
      "outputs": [],
      "source": [
        "tokenizer_for_embeddings = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "model_for_embeddings = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "qYVtmB5yeFZE"
      },
      "outputs": [],
      "source": [
        "!pip install -q scikit-learn matplotlib seaborn\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "lZXRbb_OeKvE"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer().fit_transform(chunks)\n",
        "cos_sim_matrix = cosine_similarity(vectorizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "8RdoywsTjzfe"
      },
      "outputs": [],
      "source": [
        "adj_similarities = [cos_sim_matrix[i, i+1] for i in range(len(chunks) - 1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqRwQtLoj2M-",
        "outputId": "81e2c92c-4532-41d5-d079-d3cb7bee50f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Avg similarity between adjacent chunks: 0.295\n",
            "⬇️ Lowest similarity pairs:\n",
            "Chunk 103 ↔ Chunk 104: 0.000\n",
            "Chunk 7 ↔ Chunk 8: 0.068\n",
            "Chunk 38 ↔ Chunk 39: 0.076\n",
            "Chunk 47 ↔ Chunk 48: 0.095\n",
            "Chunk 102 ↔ Chunk 103: 0.104\n"
          ]
        }
      ],
      "source": [
        "print(f\"🔍 Avg similarity between adjacent chunks: {sum(adj_similarities)/len(adj_similarities):.3f}\")\n",
        "print(\"⬇️ Lowest similarity pairs:\")\n",
        "for i, sim in sorted(enumerate(adj_similarities), key=lambda x: x[1])[:5]:\n",
        "  print(f\"Chunk {i} ↔ Chunk {i+1}: {sim:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "Wf6_9IPoj4hD",
        "outputId": "20f0f769-ee15-4b6b-f0d8-634d3433075c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap([adj_similarities], cmap='coolwarm', xticklabels=False, yticklabels=[\"Sim(i↔i+1)\"])\n",
        "plt.title(\"Adjacent Chunk Cosine Similarity\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqfWTVRKj8gC",
        "outputId": "77ad4b56-aa6e-4351-cc64-29a66fe18836"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating Embeddings For All Articles:: 100%|██████████| 54/54 [00:00<00:00, 59.93it/s]\n"
          ]
        }
      ],
      "source": [
        "def Data_generate_embeddings(text):\n",
        "    inputs = tokenizer_for_embeddings(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model_for_embeddings(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
        "\n",
        "articles = df_filtered['Text'].tolist()\n",
        "article_embeddings = []\n",
        "for doc in tqdm(articles, desc=\"Generating Embeddings For All Articles:\"):\n",
        "    article_embeddings.append(Data_generate_embeddings(doc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJ7tP-FwkJRz",
        "outputId": "e2f0474d-68c5-435c-ed27-0c0a7942358d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimension: 384 \n",
            "Vectors: [-1.70920581e-01 -1.55876279e-01  2.24563718e-01  2.68188953e-01\n",
            "  5.47947362e-02  2.64219195e-01 -1.80756718e-01 -9.94288027e-02\n",
            "  1.72627330e-01 -4.12444592e-01  2.01898515e-01  1.83579594e-01\n",
            " -4.34286706e-03 -7.25657791e-02  5.49833067e-02 -3.29408914e-01\n",
            "  1.06437370e-01  1.28079161e-01 -1.93796039e-01  1.31557152e-01\n",
            "  6.60928711e-02 -6.44139796e-02 -5.54799587e-02 -4.15268354e-02\n",
            "  1.58379544e-02  2.65955180e-02 -3.76993179e-01 -2.07289726e-01\n",
            " -7.77616501e-02  5.37481345e-03 -2.80924514e-02  1.48185581e-01\n",
            " -2.39358604e-01 -3.19862574e-01  7.08468556e-02 -3.57073486e-01\n",
            "  1.80302650e-01  4.46600199e-01  2.94384956e-01 -3.78886126e-02\n",
            "  1.70743719e-01 -2.20745519e-01 -3.43275309e-01 -3.72524321e-01\n",
            "  4.31355089e-02 -2.64227509e-01 -8.14965963e-02  6.71654791e-02\n",
            " -4.88458127e-01 -1.29697382e-01 -9.09350067e-02 -1.93886101e-01\n",
            "  5.04692793e-01 -6.41216785e-02 -2.70333290e-01 -1.54095795e-03\n",
            " -1.26978206e-02  1.12472102e-01  3.52656782e-01  1.23806991e-01\n",
            " -4.85263467e-01  4.16201770e-01 -4.10971344e-01  2.50181019e-01\n",
            "  6.16851091e-01 -3.98605652e-02 -1.41157150e-01 -4.56430316e-01\n",
            "  2.35908449e-01  4.28069592e-01  4.54301760e-02 -1.25650600e-01\n",
            " -1.64644301e-01 -1.23004295e-01 -3.53641927e-01 -3.88122857e-01\n",
            "  4.58840504e-02  6.55793324e-02 -2.57901371e-01 -2.15640247e-01\n",
            " -1.28163183e-02  1.58693731e-01  2.30365187e-01 -1.01693571e-01\n",
            "  5.34293503e-02 -4.30187106e-01  6.28734082e-02 -2.73224324e-01\n",
            "  3.48259360e-02 -1.41127795e-01  5.39041162e-01  3.88942778e-01\n",
            "  1.47759944e-01 -1.01449125e-01  3.62458646e-01  2.99370944e-01\n",
            " -2.60933638e-01  2.97869027e-01 -1.54187560e-01  3.40715379e-01\n",
            " -5.33925258e-02  5.49686560e-03 -5.69291949e-01 -2.47181743e-01\n",
            "  2.90244147e-02 -2.69308299e-01  1.01318739e-01 -1.72756135e-01\n",
            "  3.12776774e-01 -2.04309314e-01 -1.59953590e-02  6.80569559e-02\n",
            "  3.35576534e-01  2.64299549e-02 -2.24543706e-01  2.47009009e-01\n",
            " -1.24008536e-01  3.33342373e-01  3.73849511e-01  4.24377024e-01\n",
            "  1.01576418e-01  4.55579022e-03  2.64253557e-01  2.69319654e-01\n",
            "  2.21430808e-01 -6.83562279e-01 -4.18654650e-01 -8.77242267e-33\n",
            "  1.04302481e-01 -1.38822734e-01 -3.60024869e-01  1.92212015e-01\n",
            "  2.58269250e-01 -1.28918231e-01 -2.64910877e-01 -3.98865104e-01\n",
            "  2.63783008e-01 -1.56959053e-04  5.73097616e-02 -3.43131088e-02\n",
            " -3.54061842e-01  4.95395847e-02 -1.62424847e-01  1.44745737e-01\n",
            " -3.53370309e-01  7.99706429e-02 -2.21114174e-01  1.57094270e-01\n",
            "  8.62068087e-02 -2.94494331e-01 -2.27810033e-02 -3.89837399e-02\n",
            " -1.84830189e-01 -2.08995819e-01  6.34320080e-02  2.11399660e-01\n",
            " -3.03225756e-01  1.39833763e-01  6.61261100e-03  3.03740382e-01\n",
            "  1.10307440e-01 -3.29471409e-01 -4.73669767e-01  1.90075055e-01\n",
            "  4.37887460e-01 -3.38083506e-01 -1.48265421e-01  1.92692608e-01\n",
            " -3.90445590e-02  2.37674847e-01  5.87441549e-02 -1.69298947e-01\n",
            "  1.39760852e-01 -2.10365713e-01 -2.66751945e-01  5.02236426e-01\n",
            " -5.86607337e-01  1.20964691e-01  8.17664117e-02  1.19848333e-01\n",
            "  5.18717170e-01 -2.54726619e-01 -6.33003488e-02  7.91372180e-01\n",
            "  1.62824824e-01 -1.16975099e-01 -7.91707337e-02  5.66831836e-03\n",
            "  1.03048757e-01 -2.98712283e-01 -5.08081198e-01  5.31570688e-02\n",
            " -4.59544480e-01  2.42248967e-01  1.77768499e-01 -3.55891585e-01\n",
            "  1.89083576e-01 -2.34615773e-01 -1.04344070e-01 -1.45786047e-01\n",
            " -3.01600516e-01  4.43673413e-03  3.65838520e-02 -4.31708157e-01\n",
            " -4.04947363e-02  1.31624848e-01  4.32705553e-03 -1.88436925e-01\n",
            "  5.56332059e-02 -5.15410542e-01  5.42094707e-02 -2.80807838e-02\n",
            "  8.25895667e-02 -8.35649595e-02  4.08696979e-01 -2.60704458e-01\n",
            " -3.14326882e-02  4.79422122e-01  3.24473321e-01  1.18039422e-01\n",
            "  2.01062649e-01 -2.33719155e-01 -3.89785096e-02 -1.11416381e-32\n",
            "  1.66371226e-01  5.89996099e-01  1.62854359e-01 -2.43722007e-01\n",
            " -6.30691051e-02  1.91248879e-01  7.45337978e-02 -4.64539468e-01\n",
            " -2.72659183e-01 -5.78789264e-02 -3.60941477e-02  5.35377562e-01\n",
            "  4.29366350e-01  2.69294693e-03  2.76941299e-01 -2.28460059e-01\n",
            "  9.85124260e-02  6.71716556e-02 -2.89912999e-01 -2.60076106e-01\n",
            " -3.51630412e-02 -3.54857370e-02  2.59085558e-02 -3.93520355e-01\n",
            " -2.72028446e-01 -1.74846753e-01  1.99885353e-01  7.20428154e-02\n",
            " -6.02486134e-01  1.04967073e-01 -4.10604700e-02  2.79565185e-01\n",
            " -4.21368122e-01  7.51659945e-02  3.54070008e-01  4.63665903e-01\n",
            " -2.90506959e-01  2.69697644e-02 -4.29148167e-01 -1.73120484e-01\n",
            " -8.00825655e-02  3.25460464e-01  8.47268254e-02 -3.69746208e-01\n",
            " -1.25619680e-01 -1.43717200e-01  6.69733882e-01  2.52286643e-02\n",
            " -2.49072127e-02  1.47096366e-01 -4.80365306e-02  4.99488592e-01\n",
            " -8.01921785e-02  2.52591640e-01 -4.38533723e-03 -1.36454165e-01\n",
            "  5.76125741e-01 -6.18903279e-01 -6.31677806e-01 -2.27945030e-01\n",
            " -5.36138058e-01  7.36365855e-01 -4.60419178e-01 -1.60374209e-01\n",
            "  7.12503433e-01  8.74326974e-02 -1.70050293e-01  1.49154618e-01\n",
            "  1.89917490e-01  1.28368482e-01  1.32684648e-01 -6.47957623e-01\n",
            " -2.94010818e-01  3.09492685e-02  7.93527588e-02  1.93839237e-01\n",
            " -1.90157473e-01  2.28633821e-01 -1.35900468e-01 -3.42404306e-01\n",
            " -4.59559828e-01  1.82765294e-02  1.39506966e-01 -1.00024864e-01\n",
            " -2.53985882e-01 -7.17520565e-02 -2.99846902e-02 -4.90756392e-01\n",
            "  4.53536153e-01 -1.89290464e-01  1.66627884e-01  1.23441070e-01\n",
            "  1.19202200e-03 -4.43567097e-01  4.05980557e-01 -1.00704398e-07\n",
            " -1.47197634e-01 -3.95195544e-01  7.81689361e-02  5.30087888e-01\n",
            "  6.98533207e-02 -3.60555589e-01  3.35844040e-01 -3.70823629e-02\n",
            " -6.21426344e-01  1.75211161e-01 -1.33298606e-01  3.91894951e-02\n",
            "  2.80715585e-01  1.32711872e-01  2.36626804e-01 -1.40096575e-01\n",
            "  5.61909080e-01 -4.48721766e-01 -3.70038986e-01 -1.31018654e-01\n",
            " -6.19156426e-03  3.88140261e-01  1.07011244e-01  3.43202293e-01\n",
            " -5.83422542e-01  2.88724780e-01  3.31862539e-01  3.12031329e-01\n",
            " -4.42677103e-02  1.02320351e-01 -3.27286497e-02  2.03911588e-01\n",
            "  1.11149296e-01  1.39106959e-01 -1.71342015e-01  6.33234531e-02\n",
            " -4.56480384e-01  3.28166574e-01  2.23641023e-01  7.21052110e-01\n",
            "  3.09068739e-01 -3.30589682e-01  4.48988974e-01  3.29033464e-01\n",
            " -8.83258358e-02  8.93748105e-02  5.59008941e-02 -2.38322735e-01\n",
            " -7.10337469e-03  1.41861871e-01  3.44040133e-02  3.40143651e-01\n",
            "  4.15378183e-01  3.74211878e-01 -4.97103393e-01 -1.30164353e-02\n",
            " -5.21961331e-01  1.59751460e-01 -2.14218602e-01 -1.09851398e-01\n",
            "  8.35003108e-02 -1.08185038e-01 -2.42907956e-01 -3.50161791e-01]\n"
          ]
        }
      ],
      "source": [
        "print(f\"Dimension: {len(article_embeddings[7])} \\nVectors: {article_embeddings[7]}\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "WPOF8FVxkSkP"
      },
      "outputs": [],
      "source": [
        "with open('embedding.pkl', 'wb') as f:\n",
        "    pickle.dump(article_embeddings, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "D8RQBUURkWrb"
      },
      "outputs": [],
      "source": [
        "with open('embedding.pkl', 'rb') as f:\n",
        "    article_embeddings = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "8Q6lt83ekaFK"
      },
      "outputs": [],
      "source": [
        "dimension = len(article_embeddings[0])\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(np.array(article_embeddings))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "wnigGVWakmWJ"
      },
      "outputs": [],
      "source": [
        "def data_retrieve_documents(query_embedding, k):\n",
        "    distances, indices = index.search(np.array([query_embedding]), k)\n",
        "    return indices[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "wQG4KK08ko9P"
      },
      "outputs": [],
      "source": [
        "question = \" লেখক পরিচিতি  প্রকৃত নাম?\"\n",
        "question_embeddings = Data_generate_embeddings(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jmcs_ZVjksin",
        "outputId": "47e85422-ffba-43a5-f013-d59509335328"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 2, 40, 39])"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retrieved_articles_indices = data_retrieve_documents(question_embeddings, 3)\n",
        "retrieved_articles_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "4ZaP4nOFkxs-"
      },
      "outputs": [],
      "source": [
        "model_name = \"t5-base\"\n",
        "tokenizer_t5_base = T5Tokenizer.from_pretrained(model_name, legacy=False)\n",
        "model_t5_base = T5ForConditionalGeneration.from_pretrained(model_name).to(device)\n",
        "def query_answer_by_t5(question, context, max_length=150):\n",
        "    input_text = f\"question: {question} context: {context}\"\n",
        "    input_ids = tokenizer_t5_base.encode(input_text, return_tensors=\"pt\").to(device)\n",
        "    outputs = model_t5_base.generate(input_ids, max_length=max_length, num_beams=5, early_stopping=True, return_dict_in_generate=True,output_scores=True)\n",
        "    answer = tokenizer_t5_base.decode(outputs.sequences[0], skip_special_tokens=True)\n",
        "\n",
        "    logits = torch.stack(outputs.scores, dim=1)\n",
        "    probabilities = softmax(logits, dim=-1)\n",
        "    gen_sequence_indices = outputs.sequences[:, 1:].unsqueeze(-1)\n",
        "    probabilities = probabilities[:, :gen_sequence_indices.shape[1], :]\n",
        "    generated_token_probs = probabilities.gather(2, gen_sequence_indices).squeeze(-1)\n",
        "    avg_confidence = generated_token_probs.mean().item()\n",
        "    return answer, avg_confidence\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "MmwGJkg5k5aB"
      },
      "outputs": [],
      "source": [
        "all_answers = []\n",
        "for idx in retrieved_articles_indices:\n",
        "    answer_entry = {}\n",
        "    answer_entry['question'] = question\n",
        "    answer_entry['title'] = chunks[idx]  # Use chunks[idx] instead of df_filtered['Text'][idx]\n",
        "    answer, confidence = query_answer_by_t5(question, chunks[idx]) # Use chunks[idx] here too\n",
        "    answer_entry['answer'] = answer\n",
        "    answer_entry['confidence'] = confidence\n",
        "    all_answers.append(answer_entry)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKYp9SdilIUO",
        "outputId": "37878e49-52b0-4bde-d550-5543511ed895"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'question': ' লেখক পরিচিতি  প্রকৃত নাম?',\n",
              "  'title': '। পিতৃহীন দীপুর চাচাই ছিলেন পরিবারের কর্তা। দীপু শিক্ষিত হলেও তার সিদ্ধান্ত নেওয়ার ক্ষমতা ছিল না। চাচা তার বিয়ের উদ্যোগ নিলেও যৌতুক নিয়ে বাড়াবাড়ি করার কারণে কন্যার পিতা অপমানিত বোধ করে বিয়ের আলোচনা ভেঙে দেন। দীপু মেয়েটির ছবি দেখে মুগ্ধ হলেও তার চাচাকে কিছুই বলতে পারেননি। ৩। দীপুর চাচার সঙ্গে অপরিচিতা গন্সের কোন চরিত্রের মিল আছে? ক হরিশের খ মামার গ শিক্ষকের ঘ বিনুর ৪ উক্ত চরিত্রে প্রাধান্য পেয়েছে দৌরাত্ম হীনম্মন্যতা লোভ নিচের কোনটি ঠিক? ক।। ও খ। ও গ।ও ঘ।, ও ৫ অনুপমের বয়স কত বছর? ক পঁচিশ খ ছাবিবিশ গ সাতাশ ঘ আটাশ কতগুলো প্রশ্নের সঠিক উত্তর দিতে পারলে?',\n",
              "  'answer': '',\n",
              "  'confidence': 0.7877141833305359},\n",
              " {'question': ' লেখক পরিচিতি  প্রকৃত নাম?',\n",
              "  'title': '। এ গল্প নিশ্চয় তারা বিশপঁচিশ বার শনিয়াছে। মেয়েদের কেন যে এত আগ্রহ তাহা বুঝিলাম। সেই সুধাকণ্ঠের সোনার কাঠিতে সকল কথা যে সোনা হইয়া ওঠে। মেয়েটির সমস্ত শরীর মন যে একেবারে প্রাণে ভরা, তার সমস্ত চলায় বলায় স্পর্শে প্রাণ ঠিকরিয়া ওঠে। তাই মেয়েরা যখন তার মুখে গল্প শোনে তখন, গল্প নয়, তাহাকেই শোনে তাহাদের হৃদয়ের উপর প্রাণের ঝর্না ঝরিয়া পড়ে। তার সেই উদ্ভাসিত প্রাণ আমার তুলিল আমার মনে হইল, আমাকে যে প্রকৃতি তাহার আকাশ দিয়া বেষ্টন করিয়াছে সে এ তরুণীরই অক্লান্ত অল্লান প্রাণের বিশ্বব্যাপী বিস্তার।পরের স্টেশনে পৌঁছিতেই খাবারওয়ালাকে ডাকিয়া সে খুব খানিকটা চানামুঠ কিনিয়া লইল এবং লাগিল। আমার প্রকৃতি যে জাল দিয়া বেড়াআমি কেন বেশ সহজে হাসিমুখে মেয়েটির কাছে এই চানা একমুঠো চাহিয়া লইতে পারিলাম না। হাত বাড়াইয়া দিয়া কেন আমার লোভ স্বীকার করিলাম না',\n",
              "  'answer': '',\n",
              "  'confidence': 0.8258021473884583},\n",
              " {'question': ' লেখক পরিচিতি  প্রকৃত নাম?',\n",
              "  'title': 'লুল জআললাইন ব্যাচ ১? না যেটা তাহাকে ছাড়াইয়া বিশেষ করিয়া চোখে পড়িতে পারে। সে নিজের চারি দিকের সকলের চেয়ে অধিক রজনীগন্ধার শুভ্র মঞ্জরীর মতো সরল বৃন্তটির উপরে দীড়াইয়া, যে গাছে ফুটিয়াছে সে গাছকে সে একেবারে অতিক্রম করিয়া উঠিয়াছে। সঙ্গে দুটিতিনটি ছোটো ছোটো মেয়ে ছিল, তাহাদিগকে লইয়া তাহার হাসি এবং কথার আর অন্ত ছিল না। আমি হাতে একখানা বই লইয়া সে দিকে কান পাতিয়া রাখিয়াছিলাম। যেটুকু কানে আসিতেছিল সে তো সমস্তই ছেলেমানুষদের সঙ্গে ছেলেমানুষি কথা। তাহার বিশেষত্ব এই যে, তাহার মধ্যে বয়সের তফাত কিছুমাত্র ছিল না ছোটোদের সঙ্গে সে অনায়াসে এবং আনন্দে ছোটো হইয়া গিয়াছিল। সঙ্গে কতকগলি ছবিওয়ালা ছেলেদের গল্পের বইতাহারই কোন একটা বিশেষ গল্প শোনাইবার জন্য মেয়েরা তাহাকে ধরিয়া পড়িল। এ গল্প নিশ্চয় তারা বিশপঁচিশ বার শনিয়াছে। মেয়েদের কেন যে এত আগ্রহ তাহা বুঝিলাম',\n",
              "  'answer': '',\n",
              "  'confidence': 0.8176944851875305}]"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8npWcXGJlLFP",
        "outputId": "ac48f5a0-6a2b-4d18-e6a0-6b98c873e49f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'question': ' লেখক পরিচিতি  প্রকৃত নাম?',\n",
              " 'title': '। এ গল্প নিশ্চয় তারা বিশপঁচিশ বার শনিয়াছে। মেয়েদের কেন যে এত আগ্রহ তাহা বুঝিলাম। সেই সুধাকণ্ঠের সোনার কাঠিতে সকল কথা যে সোনা হইয়া ওঠে। মেয়েটির সমস্ত শরীর মন যে একেবারে প্রাণে ভরা, তার সমস্ত চলায় বলায় স্পর্শে প্রাণ ঠিকরিয়া ওঠে। তাই মেয়েরা যখন তার মুখে গল্প শোনে তখন, গল্প নয়, তাহাকেই শোনে তাহাদের হৃদয়ের উপর প্রাণের ঝর্না ঝরিয়া পড়ে। তার সেই উদ্ভাসিত প্রাণ আমার তুলিল আমার মনে হইল, আমাকে যে প্রকৃতি তাহার আকাশ দিয়া বেষ্টন করিয়াছে সে এ তরুণীরই অক্লান্ত অল্লান প্রাণের বিশ্বব্যাপী বিস্তার।পরের স্টেশনে পৌঁছিতেই খাবারওয়ালাকে ডাকিয়া সে খুব খানিকটা চানামুঠ কিনিয়া লইল এবং লাগিল। আমার প্রকৃতি যে জাল দিয়া বেড়াআমি কেন বেশ সহজে হাসিমুখে মেয়েটির কাছে এই চানা একমুঠো চাহিয়া লইতে পারিলাম না। হাত বাড়াইয়া দিয়া কেন আমার লোভ স্বীকার করিলাম না',\n",
              " 'answer': '',\n",
              " 'confidence': 0.8258021473884583}"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "highest_conf = -1\n",
        "for answer in all_answers:\n",
        "    if highest_conf < answer['confidence']:\n",
        "        highest_conf = answer['confidence']\n",
        "        answer_with_reference = answer\n",
        "answer_with_reference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "jkC9UTcdlUhL"
      },
      "outputs": [],
      "source": [
        "# Fix: Access chunks directly using the retrieved indices\n",
        "retrieved_text_articles = [chunks[i] for i in retrieved_articles_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "ngsc6rFrlb13"
      },
      "outputs": [],
      "source": [
        "def processing_context(docs, max_tokens=1536):\n",
        "    processed_docs = []\n",
        "    total_tokens = 0\n",
        "    for doc in docs:\n",
        "        tokens = len(doc.split())\n",
        "        if total_tokens + tokens <= max_tokens:\n",
        "            processed_docs.append(doc)\n",
        "            total_tokens += tokens\n",
        "        else:\n",
        "            break\n",
        "    return \"\\n\".join(f\"- {doc}\" for doc in processed_docs)\n",
        "\n",
        "final_retrived_contexts = processing_context(retrieved_text_articles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKDQVBCVlfm9"
      },
      "outputs": [],
      "source": [
        "client = OpenAI(api_key='sk-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX')\n",
        "def answer_by_gpt4_turbo(question, contexts, max_tokens):\n",
        "    prompt = f\"\"\"Answer the question based on the provided context. If the context doesn't contain the answer, say \"Sorry! I don't have enough information to answer that.\"\n",
        "    **Question:** {question}\n",
        "    **Context:** {contexts}\n",
        "    \"\"\"\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are an intelligent assistant that answers questions based on the provided context.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=messages,\n",
        "        max_tokens=max_tokens,\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "yQjzRNcamAms",
        "outputId": "4dbbd021-72f6-46a0-8f7f-143fc1aaf579"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Sorry! I don't have enough information to answer that.\""
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "answer_gpt4 = answer_by_gpt4_turbo(question, final_retrived_contexts ,250)\n",
        "answer_gpt4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xiK8iEGoJ_c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
